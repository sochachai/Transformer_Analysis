{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1YMmKE6T4PEUthCdLd_Ec5hTK2zgZ6K2p",
      "authorship_tag": "ABX9TyPHhCceP+FTE3R281TAOunH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sochachai/Transformer_Analysis/blob/main/Letter_Decryption.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load packages"
      ],
      "metadata": {
        "id": "QadEcdM9HWsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check directory\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8gwuRviI0JD",
        "outputId": "ff305cca-cda6-4911-fa0d-fd9baf6fd9e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_file = 'drive/MyDrive/original_document' + '/original_document' + '_'\\\n",
        "                          + str(0 + 0) + '.txt'\n",
        "with open(original_file, 'r') as file:\n",
        "            original_sentences = file.readlines()"
      ],
      "metadata": {
        "id": "1kaEMHIWglIj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confirm the assistant py file has been uploaded to the correct directory\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj093MmNI24A",
        "outputId": "032c3e9f-eae3-4251-ac25-2409b2cea49c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encripted_document.txt\tmy_transformer_utils.py  original_document.txt\t__pycache__  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check Python version\n",
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9lyQC3sJbJs",
        "outputId": "c3be1051-0cb6-46c2-8431-7b72ca0cab0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install torch\n",
        "!pip install torch==2.2.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRb0L4jOJzuY",
        "outputId": "9bff65ec-ed42-4fa0-e98d-08e3065ce548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.2.0\n",
            "  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.0) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.2.0 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.2.0 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 torch-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check torch version\n",
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AWYB4ZIJnlB",
        "outputId": "0c78a336-93fc-4a17-f8e4-25113304c902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZL5Plt3mvusS"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch\n",
        "import math\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "# Issue caused by torch version described below:\n",
        "# the original package should be pyitcast.transformer_utils\n",
        "# the problem is that pyitcast.transformer_utils relies on an old version of torch (1.3.1 should work)\n",
        "# and causes the error \"IndexError: invalid index of a 0-dim tensor. Use `tensor.item()` in Python...\"\n",
        "# but the installation of an old version of torch that match pyitcast.transformer is not trivial\n",
        "# versions of 1.11.0 or after is not compatible with pyitcast.transformer and installation of them will not\n",
        "# solve the issue\n",
        "# To solve this issue:\n",
        "# download the pyitcast.transformer_utils (open by clicking the error message) as a py file\n",
        "# modify the last line of the SimpleLossCompute class from \"return loss.data[0] * norm\"\n",
        "# to \"return loss.data * norm\"\n",
        "\n",
        "from my_transformer_utils import Batch\n",
        "from my_transformer_utils import run_epoch\n",
        "from my_transformer_utils import greedy_decode\n",
        "from my_transformer_utils import get_std_opt # get_std_opt is based on Adam optimizer\n",
        "from my_transformer_utils import LabelSmoothing # offset human label errors to prevent overfitting\n",
        "from my_transformer_utils import SimpleLossCompute # calculate loss after smoothing, use cross_entropy_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construct the class of Embeddings and Positional Encoding."
      ],
      "metadata": {
        "id": "UBTCCLP4Hc3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        '''\n",
        "        :param d_model: embedding dimension\n",
        "        :param vocab: size of vocabulary\n",
        "        '''\n",
        "        # Initialization\n",
        "        super(Embeddings, self).__init__()\n",
        "        # Defrine a word embedding object\n",
        "        self.lut = nn.Embedding(vocab, d_model)\n",
        "        # Instantiate d_model\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        :param x: tensor representing the original text\n",
        "        '''\n",
        "        return self.lut(x) * math.sqrt(self.d_model)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout, max_len = 5000):\n",
        "        '''\n",
        "        :param d_model: dimension of the encoding\n",
        "        :param dropout: dropout rate from 0 to 1\n",
        "        :param max_len: the maximum length of a sentence\n",
        "        '''\n",
        "        # Inherit the initialization of nn.Module\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        # Objectify dropout\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Inherit a positional encoder matrix, max_len * d_model\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "\n",
        "        # Inherit an absolute position matrix, max_len * 1\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "\n",
        "        # Define the conversion matrix, initialization with gap = 2\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0)/d_model))\n",
        "\n",
        "        # Copy the absolute position matrix to the positional encoder matrix\n",
        "        # by sine and cosine wave according to the parity of column indices\n",
        "        pe[:, 0::2] = torch.sin(position * div_term) # even indiced columns are imputed by sine\n",
        "        pe[:, 1::2] = torch.cos(position * div_term) # odd indiced columns are imputed by cosine\n",
        "\n",
        "        # Extend pe to 3-dimensional tensor\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        # Register pe to a buffer, the buffer is not a parameter of the class\n",
        "        # the buffer will not be updated along with the model update\n",
        "        # but it can be loaded along with the model\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        :param x: Tensor of text\n",
        "        :return: x + the positional encoding\n",
        "        '''\n",
        "        # Shrink the size of pe to save storage\n",
        "        # by converting the second dimension, i.e. the dimension of max_len\n",
        "        # to the size of the sentence len of x, i.e. the second dimension of x\n",
        "        x = x + Variable(self.pe[:,:x.size(1)], requires_grad = False) # False: pe will not be updated\n",
        "        return self.dropout(x)\n",
        "\n",
        "def attention(query, key, value, mask = None, dropout = None):\n",
        "    '''\n",
        "    :param query: vectorized original text\n",
        "    :param key: key words of text\n",
        "    :param value: the original value of key, summarization of query\n",
        "    :param mask: hide words to avoid data leakage\n",
        "    :param dropout: dropout rate of neural network\n",
        "    :return:\n",
        "    '''\n",
        "    d_k = query.size(-1)\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, -1e9) # compare each position with 0\n",
        "\n",
        "    p_attn = F.softmax(scores, dim = -1)\n",
        "    if dropout is not None:\n",
        "        p_attn = dropout(p_attn)\n",
        "\n",
        "    return torch.matmul(p_attn, value), p_attn\n",
        "\n",
        "def clones(module, N):\n",
        "    '''\n",
        "    :param module: one attention layer\n",
        "    :param N: the number of module\n",
        "    '''\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)]) # deepcopy uses a different memory\n",
        "\n",
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, head, embedding_dim, dropout = 0.1):\n",
        "        '''\n",
        "        :param head: the number of heads\n",
        "        :param embedding_dim: the embedding dimension\n",
        "        :param dropout: default dropout rate set to 0.1\n",
        "        '''\n",
        "        # Inherit the initialization\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        # head must be an integral factor of embedding_dim\n",
        "        assert embedding_dim % head == 0\n",
        "        # each head is assigned with the following dimension\n",
        "        self.d_k = embedding_dim // head # division in the integral domain Z\n",
        "        # substantiate head\n",
        "        self.head = head\n",
        "        # create linear layers, we need 4 of them for Q, K, V and the final connection\n",
        "        self.linears = clones(nn.Linear(embedding_dim, embedding_dim), 4)\n",
        "        # create the attention and dropout rate\n",
        "        self.attn = None\n",
        "        self.dropout = nn.Dropout(p = dropout)\n",
        "\n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1)\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        # We have 4 linears and only zipping the first 3 with Q, K, V, the last linear is not used.\n",
        "        # view(batch_size, -1, self.head, self.d_k).transpose(1,2)\n",
        "        # is not the same with view(batch_size, self.head, -1, self.d_k)\n",
        "        # self.head and self.d_k should be neighboring to get embedding_dim in order for the tensor\n",
        "        # to interpret the relationship between the meaning of words of their positions in a sentence\n",
        "\n",
        "        query, key, value = \\\n",
        "            [model(x).view(batch_size, -1, self.head, self.d_k).transpose(1,2)\n",
        "             for model, x in zip(self.linears, (query, key, value))]\n",
        "\n",
        "        x, self.attn = attention(query, key, value, mask = mask, dropout = self.dropout)\n",
        "\n",
        "        # Reshape x\n",
        "        # must use contiguous method after the transpose before the view method\n",
        "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.head * self.d_k)\n",
        "\n",
        "        # Pass x to the 4th linear layer\n",
        "        return self.linears[-1](x)\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        '''\n",
        "        :param d_model: embedding dimension\n",
        "        :param d_ff: transitional dimension\n",
        "        :param dropout: default dropout set to 0.1\n",
        "        '''\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.w1 = nn.Linear(d_model, d_ff)\n",
        "        self.w2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w2(self.dropout(F.relu(self.w1(x))))\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, features, eps = 1e-6):\n",
        "        '''\n",
        "        :param features: embedding dimension\n",
        "        :param eps: avoid zero denominator\n",
        "        '''\n",
        "        super(LayerNorm, self).__init__()\n",
        "        # nn.Parameter formats the variables to intrinsic parameters\n",
        "        # they will be updated along with the model in contrast with buffer\n",
        "        self.a2 = nn.Parameter(torch.ones(features))\n",
        "        self.b2 = nn.Parameter(torch.zeros(features))\n",
        "        # initialization of eps\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        :param x: the output of previous layer\n",
        "        :return: numerical standardized x\n",
        "        '''\n",
        "        mean = x.mean(-1, keepdim = True)\n",
        "        std = x.std(-1, keepdim = True)\n",
        "        return self.a2 * (x - mean) / (std + self.eps) + self.b2\n",
        "\n",
        "class SublayerConnection(nn.Module):\n",
        "    def __init__(self, size, dropout = 0.1):\n",
        "        '''\n",
        "        :param size: embedding size\n",
        "        :param dropout: deactivation of neurons to avoid overfitting\n",
        "        '''\n",
        "        super(SublayerConnection, self).__init__()\n",
        "        self.norm = LayerNorm(size)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        '''\n",
        "        :param x: the output of previous layer\n",
        "        :param sublayer: a function, e.g. Multihead_Attention, PositionwiseFeedForward etc.\n",
        "        :return: x plus sublayer functioning on normed x with dropout\n",
        "        '''\n",
        "        return x + self.dropout(sublayer(self.norm(x)))\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "        '''\n",
        "        :param size: embedding dimension\n",
        "        :param self_attn: attention\n",
        "        :param feed_forward: positionwise feed forward\n",
        "        :param dropout: avoid overfitting\n",
        "        '''\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = self_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
        "        self.size = size\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        '''\n",
        "        :param x: output of previous layer\n",
        "        :param mask: tensor mask to prevent data leakage\n",
        "        '''\n",
        "        # input matrix followed by operating function, returns an output matrix\n",
        "        # sublayer(x, function) will return function(x)\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask)) # the forward function of multihead attention\n",
        "        return self.sublayer[1](x, self.feed_forward) # the forward function of pointwise feedforward\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    # Encoder is a collection of Encoder Layers\n",
        "    def __init__(self, layer, N):\n",
        "        '''\n",
        "        :param layer: one encoder layer\n",
        "        :param N: the number of encoder layers\n",
        "        '''\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        for layer in self.layers: x = layer(x, mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
        "        '''\n",
        "        :param size: embedding dimension\n",
        "        :param self_attn: masked multihead attention\n",
        "        :param src_attn: multihead attention\n",
        "        :param feed_forward: pointwise feed forward\n",
        "        :param dropout: avoid overfitting\n",
        "        '''\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.src_attn = src_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        # 3 sublayer for a decoder layer\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
        "\n",
        "    def forward(self, x, memory, source_mask, target_mask):\n",
        "        '''\n",
        "        :param x: output of previous layer\n",
        "        :param memory: result of encoder\n",
        "        :param source_mask: delete unnecessary info to improve model performance\n",
        "        :param target_mask: hide info to prevent data leakage\n",
        "        :return: output tensor\n",
        "        '''\n",
        "        m = memory\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, target_mask))\n",
        "        # for second layer, Q = x, K = V = m\n",
        "        x = self.sublayer[1](x, lambda x: self.self_attn(x, m, m, source_mask))\n",
        "        return self.sublayer[2](x, self.feed_forward)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    # Decoder is a collection of Decoder Layers\n",
        "    def __init__(self, layer, N):\n",
        "        '''\n",
        "        :param layer: decoder layer\n",
        "        :param N: the number of decoder layers\n",
        "        '''\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, memory, source_mask, target_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, memory, source_mask, target_mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, d_model, vocab_size):\n",
        "        '''\n",
        "        :param d_model: embedding dimension\n",
        "        :param vocab_size: the size of the vocabulary\n",
        "        '''\n",
        "        super(Generator, self).__init__()\n",
        "        self.project = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.project(x), dim = -1)\n",
        "\n",
        "class EncoderDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder, source_embed, target_embed, generator):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = source_embed\n",
        "        self.tgt_embed = target_embed\n",
        "        self.generator = generator\n",
        "\n",
        "    def forward(self, source, target, source_mask, target_mask):\n",
        "        # encoded source used as memory in decode function\n",
        "        return self.decode(self.encode(source, source_mask), source_mask,\n",
        "                           target, target_mask)\n",
        "\n",
        "    def encode(self, source, source_mask):\n",
        "        return self.encoder(self.src_embed(source), source_mask)\n",
        "\n",
        "    def decode(self, memory, source_mask, target, target_mask):\n",
        "        # embedded target as x in the decoder function\n",
        "        return self.decoder(self.tgt_embed(target), memory, source_mask, target_mask)\n",
        "\n",
        "def make_model(source_vocab, target_vocab, N=6,\\\n",
        "               d_model=512, d_ff=2048, head=8, dropout=0.1):\n",
        "    c = copy.deepcopy\n",
        "    attn = MultiHeadedAttention(head, d_model)\n",
        "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "    position = PositionalEncoding(d_model, dropout)\n",
        "    model = EncoderDecoder(\n",
        "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
        "        Decoder(DecoderLayer(d_model, c(attn), c(attn),c(ff), dropout), N),\n",
        "        # note the order of vocab_size and d_model;\n",
        "        # nn.Embedding is not the same with Embeddings;\n",
        "        # check Embedding_Encoder.py for more;\n",
        "        nn.Sequential(Embeddings(d_model, source_vocab), c(position)),\n",
        "        nn.Sequential(Embeddings(d_model, target_vocab), c(position)),\n",
        "        Generator(d_model, target_vocab)\n",
        "    )\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1: nn.init.xavier_uniform_(p) # initialization: make p uniformly sampled; check xavier_uniform for details\n",
        "    return model\n",
        "\n",
        "# use a function to generate data\n",
        "def data_generator(V, batch_size, num_batch):\n",
        "    '''\n",
        "    :param V: the maximal data value + 1\n",
        "    :param batch_size: sample data size of one round of training after which model parameters are updated\n",
        "    :param num_batch: number of rounds of training\n",
        "    '''\n",
        "    for i in range(num_batch):\n",
        "        # data value from 1 to V-1, with data matrix shape = batch_size times 10\n",
        "        data = torch.from_numpy(np.random.randint(1, V, size = (batch_size, 40)))\n",
        "\n",
        "        # set starting position label\n",
        "        data[:, 0] = 1\n",
        "\n",
        "        # for a copy task source data and target data should be the same\n",
        "        # no gradient calculation involved\n",
        "        source = Variable(data, requires_grad = True)\n",
        "        target = Variable(data, requires_grad = True)\n",
        "        #print(f\"source is {source}\")\n",
        "        #return Batch(source, target)\n",
        "        yield Batch(source, target)\n",
        "\n",
        "def data_generator_letter(batch_size, num_batch, initial_document_index):\n",
        "    '''\n",
        "    :param batch_size: sample data size of one round of training after which model parameters are updated\n",
        "                       how many sentences\n",
        "    :param num_batch: number of rounds of training\n",
        "                      how many text documents\n",
        "    '''\n",
        "    fix_letter_indicator_value = 0\n",
        "    max_sentence_len = 40\n",
        "    for i in range(num_batch):\n",
        "        original_file = 'drive/MyDrive/original_document' + '/original_document' + '_'\\\n",
        "                          + str(i + initial_document_index) + '.txt'\n",
        "        with open(original_file, 'r') as file:\n",
        "            original_sentences = file.readlines()\n",
        "        encrypted_file = 'drive/MyDrive/encrypted_document' + '/encrypted_document' + '_'\\\n",
        "                          + str(i + initial_document_index) + '.txt'\n",
        "        with open(encrypted_file, 'r') as file:\n",
        "            encrypted_sentences = file.readlines()\n",
        "\n",
        "        # Limit Number of sentences\n",
        "        original_sentences = original_sentences[0:batch_size]\n",
        "        #original_sentences = original_sentences[batch_size * 1 : batch_size * (1+1)]\n",
        "        original_sentences = [sentence.rstrip('\\n').lower() for sentence in original_sentences]\n",
        "\n",
        "        # Limit Number of sentences\n",
        "        encrypted_sentences = encrypted_sentences[0:batch_size]\n",
        "        encrypted_sentences = [sentence.rstrip('\\n').lower() for sentence in encrypted_sentences]\n",
        "\n",
        "        def get_numeric(symbol):\n",
        "            if symbol == 'a': return 1\n",
        "            elif symbol == 'b': return 2\n",
        "            elif symbol == 'c': return 3\n",
        "            elif symbol == 'd': return 4\n",
        "            elif symbol == 'e': return 5\n",
        "            elif symbol == 'f': return 6\n",
        "            elif symbol == 'g': return 7\n",
        "            elif symbol == 'h': return 8\n",
        "            elif symbol == 'i': return 9\n",
        "            elif symbol == 'j': return 10\n",
        "            elif symbol == 'k': return 11\n",
        "            elif symbol == 'l': return 12\n",
        "            elif symbol == 'm': return 13\n",
        "            elif symbol == 'n': return 14\n",
        "            elif symbol == 'o': return 15\n",
        "            elif symbol == 'p': return 16\n",
        "            elif symbol == 'q': return 17\n",
        "            elif symbol == 'r': return 18\n",
        "            elif symbol == 's': return 19\n",
        "            elif symbol == 't': return 20\n",
        "            elif symbol == 'u': return 21\n",
        "            elif symbol == 'v': return 22\n",
        "            elif symbol == 'w': return 23\n",
        "            elif symbol == 'x': return 24\n",
        "            elif symbol == 'y': return 25\n",
        "            elif symbol == 'z': return 26\n",
        "            else: return fix_letter_indicator_value\n",
        "\n",
        "        numeric_original_text = np.empty([1,max_sentence_len])\n",
        "        for sentence_index, one_sentence in enumerate(original_sentences):\n",
        "            numeric_sentence = np.pad([get_numeric(item) for index, item in enumerate(one_sentence[:max_sentence_len])],\\\n",
        "                                      (0, max_sentence_len - len(one_sentence[:max_sentence_len])), 'constant',\\\n",
        "                                      constant_values=(fix_letter_indicator_value, fix_letter_indicator_value))\n",
        "            numeric_original_text = np.vstack((numeric_original_text, numeric_sentence))\n",
        "        # the first row of numeric_original_text is redundant\n",
        "        # attach a column of zeros in front of numeric_encrypted_text as indicators of start of sentences\n",
        "        row_num = numeric_original_text[1:,].shape[0]\n",
        "        numeric_original_text = np.hstack((np.zeros((row_num,1)),numeric_original_text[1:,]))\n",
        "        numeric_original_text = torch.from_numpy(numeric_original_text)\n",
        "\n",
        "        numeric_encrypted_text = np.empty([1,max_sentence_len])\n",
        "        for sentence_index, one_sentence in enumerate(encrypted_sentences):\n",
        "            numeric_sentence = np.pad([get_numeric(item) for index, item in enumerate(one_sentence[:max_sentence_len])],\\\n",
        "                                      (0, max_sentence_len - len(one_sentence[:max_sentence_len])), 'constant',\\\n",
        "                                      constant_values=(fix_letter_indicator_value, fix_letter_indicator_value))\n",
        "            numeric_encrypted_text = np.vstack((numeric_encrypted_text, numeric_sentence))\n",
        "        # the first row of numeric_encrypted_text is redundant\n",
        "        # attach a column of zeros in front of numeric_encrypted_text as indicators of start of sentences\n",
        "        row_num = numeric_encrypted_text[1:,].shape[0]\n",
        "        numeric_encrypted_text = np.hstack((np.zeros((row_num,1)),numeric_encrypted_text[1:,]))\n",
        "        numeric_encrypted_text = torch.from_numpy(numeric_encrypted_text)\n",
        "        # for a copy task source data and target data should be the same\n",
        "        # no gradient calculation involved\n",
        "        source = Variable(numeric_encrypted_text, requires_grad = False)\n",
        "        target = Variable(numeric_original_text, requires_grad = False)\n",
        "        source = source.type(torch.int64)\n",
        "        target = target.type(torch.int64)\n",
        "\n",
        "        #print(f\"source is {source}\")\n",
        "        #return Batch(source, target)\n",
        "        yield Batch(source, target)\n",
        "\n",
        "def run(model, loss, epochs=10):\n",
        "    '''\n",
        "    :param model: model\n",
        "    :param loss: loss function\n",
        "    :param epochs: number of rounds of training\n",
        "    '''\n",
        "    for epoch in range(epochs):\n",
        "        # train model, update model parameters\n",
        "        model.train()\n",
        "        run_epoch(data_generator_letter(10, 10, 0), model, loss)\n",
        "        #evaluate model, no parameters update\n",
        "        model.eval()\n",
        "        run_epoch(data_generator_letter(10, 2, 10), model, loss)\n"
      ],
      "metadata": {
        "id": "q5g__pE7CWic"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiate a model."
      ],
      "metadata": {
        "id": "KEdHXxGxHELW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate variables\n",
        "V = 27 # maximal digit + 1\n",
        "#batch_size = 20\n",
        "#num_batch = 8\n",
        "\n",
        "# get model\n",
        "model = make_model(V, V, N = 6)\n",
        "\n",
        "# get optimizer\n",
        "model_optimizer = get_std_opt(model)\n",
        "\n",
        "# get smooth criterion\n",
        "criterion = LabelSmoothing(size = V, padding_idx = 0, smoothing = 0.0)\n",
        "\n",
        "# get loss function\n",
        "# model as an EncoderDecoder whose last element is a generator object\n",
        "loss = SimpleLossCompute(model.generator, criterion, model_optimizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_FcF3EqEmy8",
        "outputId": "2e90a1e7-4441-44ea-82f0-11ea0ce08931"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 epochs of model training."
      ],
      "metadata": {
        "id": "Gf1eGbnNFeB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model training\n",
        "epochs = 10\n",
        "if __name__ == '__main__':\n",
        "    run(model, loss, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLdoV2-vsitL",
        "outputId": "1afb6f72-580d-4b31-f432-ee180d7db3b0"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch Step: 1 Loss: 0.156354 Tokens per Sec: 76.906265\n",
            "Epoch Step: 1 Loss: 0.144960 Tokens per Sec: 119.830864\n",
            "Epoch Step: 1 Loss: 0.176467 Tokens per Sec: 88.730659\n",
            "Epoch Step: 1 Loss: 0.130919 Tokens per Sec: 115.235741\n",
            "Epoch Step: 1 Loss: 0.187502 Tokens per Sec: 93.671066\n",
            "Epoch Step: 1 Loss: 0.164773 Tokens per Sec: 90.333878\n",
            "Epoch Step: 1 Loss: 0.171018 Tokens per Sec: 111.492607\n",
            "Epoch Step: 1 Loss: 0.154115 Tokens per Sec: 94.835915\n",
            "Epoch Step: 1 Loss: 0.102926 Tokens per Sec: 115.109848\n",
            "Epoch Step: 1 Loss: 0.152155 Tokens per Sec: 117.716644\n",
            "Epoch Step: 1 Loss: 0.155118 Tokens per Sec: 114.430832\n",
            "Epoch Step: 1 Loss: 0.128946 Tokens per Sec: 119.001793\n",
            "Epoch Step: 1 Loss: 0.123811 Tokens per Sec: 109.102394\n",
            "Epoch Step: 1 Loss: 0.117339 Tokens per Sec: 120.474518\n",
            "Epoch Step: 1 Loss: 0.095909 Tokens per Sec: 90.899033\n",
            "Epoch Step: 1 Loss: 0.116279 Tokens per Sec: 119.606033\n",
            "Epoch Step: 1 Loss: 0.145057 Tokens per Sec: 90.406105\n",
            "Epoch Step: 1 Loss: 0.111673 Tokens per Sec: 102.098366\n",
            "Epoch Step: 1 Loss: 0.140118 Tokens per Sec: 104.154884\n",
            "Epoch Step: 1 Loss: 0.117263 Tokens per Sec: 93.704933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the model's capibility of copying the original sequence with greedy decode after 10 epochs of training."
      ],
      "metadata": {
        "id": "HpkNeAqqr4Yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(an_integer_sequence_of_size_5):\n",
        "    # greedy decode\n",
        "    # enter evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # get source input\n",
        "    source = Variable(torch.LongTensor([an_integer_sequence_of_size_5]))\n",
        "\n",
        "    # get source mask\n",
        "    # 1 for no masking\n",
        "    source_mask = Variable(torch.ones(1, 1, 9))\n",
        "\n",
        "    # get result\n",
        "    #result = greedy_decode(model, source, source_mask, max_len=20, start_symbol=0)\n",
        "    result = greedy_decode(model, source, source_mask, max_len=40, start_symbol=0)\n",
        "    print(f\"The source numeric sequence is:\\n {source}\")\n",
        "    print(f\"The resulting numeric sequence after {epochs} epochs of training is:\\n {result}\")\n",
        "\n",
        "test_model([0,2,2,2,2,2,2,2,2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cfZ2TBzryq5",
        "outputId": "eccc3d32-04fa-415d-b854-291de741dc64"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[0, 2, 2, 2, 2, 2, 2, 2, 2]])\n",
            "The resulting numeric sequence after 50 epochs of training is:\n",
            " tensor([[ 0, 23,  5, 23, 23, 23, 23,  8,  5, 23, 23, 23,  1, 21, 20,  8,  5, 23,\n",
            "         23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,  8,  5,  5, 18,  5, 16,  5,\n",
            "         23, 23, 23, 23]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sentence_len = 40\n",
        "def en_to_num(symbol):\n",
        "    if symbol == 'a': return 1\n",
        "    elif symbol == 'b': return 2\n",
        "    elif symbol == 'c': return 3\n",
        "    elif symbol == 'd': return 4\n",
        "    elif symbol == 'e': return 5\n",
        "    elif symbol == 'f': return 6\n",
        "    elif symbol == 'g': return 7\n",
        "    elif symbol == 'h': return 8\n",
        "    elif symbol == 'i': return 9\n",
        "    elif symbol == 'j': return 10\n",
        "    elif symbol == 'k': return 11\n",
        "    elif symbol == 'l': return 12\n",
        "    elif symbol == 'm': return 13\n",
        "    elif symbol == 'n': return 14\n",
        "    elif symbol == 'o': return 15\n",
        "    elif symbol == 'p': return 16\n",
        "    elif symbol == 'q': return 17\n",
        "    elif symbol == 'r': return 18\n",
        "    elif symbol == 's': return 19\n",
        "    elif symbol == 't': return 20\n",
        "    elif symbol == 'u': return 21\n",
        "    elif symbol == 'v': return 22\n",
        "    elif symbol == 'w': return 23\n",
        "    elif symbol == 'x': return 24\n",
        "    elif symbol == 'y': return 25\n",
        "    elif symbol == 'z': return 26\n",
        "    else: return 0\n",
        "\n",
        "def num_to_en(number):\n",
        "    if number == 1: return 'a'\n",
        "    elif number == 2: return 'b'\n",
        "    elif number == 3: return 'c'\n",
        "    elif number == 4: return 'd'\n",
        "    elif number == 5: return 'e'\n",
        "    elif number == 6: return 'f'\n",
        "    elif number == 7: return 'g'\n",
        "    elif number == 8: return 'h'\n",
        "    elif number == 9: return 'i'\n",
        "    elif number == 10: return 'j'\n",
        "    elif number == 11: return 'k'\n",
        "    elif number == 12: return 'l'\n",
        "    elif number == 13: return 'm'\n",
        "    elif number == 14: return 'n'\n",
        "    elif number == 15: return 'o'\n",
        "    elif number == 16: return 'p'\n",
        "    elif number == 17: return 'q'\n",
        "    elif number == 18: return 'r'\n",
        "    elif number == 19: return 's'\n",
        "    elif number == 20: return 't'\n",
        "    elif number == 21: return 'u'\n",
        "    elif number == 22: return 'v'\n",
        "    elif number == 23: return 'w'\n",
        "    elif number == 24: return 'x'\n",
        "    elif number == 25: return 'y'\n",
        "    elif number == 26: return 'z'\n",
        "    else: return ' '\n",
        "\n",
        "def number_to_text(numbers, input_text):\n",
        "    # number_text is numeric representation of the original text without number rotation(i.e. encryption)\n",
        "    number_text = np.pad([en_to_num(item) for index, item in enumerate(input_text[:max_sentence_len])],\\\n",
        "                                      (0, max_sentence_len - len(input_text[:max_sentence_len])), 'constant',\\\n",
        "                                      constant_values=(0, 0))\n",
        "    # numbers is the predicted numeric representation\n",
        "    text = ' '\n",
        "    for index, item in enumerate(zip(numbers, number_text)):\n",
        "        if item[0] == 0:\n",
        "            text = text + str(num_to_en(item[1]))\n",
        "        else:\n",
        "            text = text + str(num_to_en(item[0]))\n",
        "    return text\n",
        "\n",
        "model.eval()\n",
        "#print([en_to_num(letter) for index, letter in enumerate(input_text)])\n",
        "input_text = 'fffff'\n",
        "# get source input\n",
        "source = Variable(torch.LongTensor([[en_to_num(letter) for index, letter in enumerate(input_text)]]))\n",
        "#print(source)\n",
        "\n",
        "# get source mask\n",
        "# 1 for no masking\n",
        "source_mask = Variable(torch.ones(1, 1, len(input_text)))\n",
        "print(source_mask)\n",
        "# get result\n",
        "result = greedy_decode(model, source, source_mask, max_len=41, start_symbol=0)\n",
        "output_text = number_to_text(result[0].tolist()[1:], input_text)\n",
        "print(result)\n",
        "print(f\"The input text is: {input_text}\")\n",
        "print(f\"The output text is: {output_text}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_O1N9XrGzgk",
        "outputId": "2766cd2a-7e53-449a-9e56-117e9a933892"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 1., 1., 1., 1.]]])\n",
            "tensor([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "The input text is: fffff\n",
            "The output text is:  aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the model's capibility of copying the original sequence with greedy decode after an extra of 20 epochs of training."
      ],
      "metadata": {
        "id": "tEXOpUlSGGiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model training\n",
        "epochs = 20\n",
        "if __name__ == '__main__':\n",
        "    run(model, loss, epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5SwQh1vGDRJ",
        "outputId": "7b9fb8a5-823e-4884-9321-127931aae86a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch Step: 1 Loss: 1.239350 Tokens per Sec: 162.733932\n",
            "Epoch Step: 1 Loss: 0.908190 Tokens per Sec: 171.653259\n",
            "Epoch Step: 1 Loss: 0.996257 Tokens per Sec: 181.329926\n",
            "Epoch Step: 1 Loss: 0.741328 Tokens per Sec: 148.147736\n",
            "Epoch Step: 1 Loss: 0.963049 Tokens per Sec: 166.191589\n",
            "Epoch Step: 1 Loss: 0.628003 Tokens per Sec: 167.297852\n",
            "Epoch Step: 1 Loss: 0.933253 Tokens per Sec: 169.863144\n",
            "Epoch Step: 1 Loss: 0.629011 Tokens per Sec: 151.229950\n",
            "Epoch Step: 1 Loss: 0.831857 Tokens per Sec: 168.031021\n",
            "Epoch Step: 1 Loss: 0.548762 Tokens per Sec: 174.622253\n",
            "Epoch Step: 1 Loss: 0.777321 Tokens per Sec: 168.225006\n",
            "Epoch Step: 1 Loss: 0.414798 Tokens per Sec: 180.782944\n",
            "Epoch Step: 1 Loss: 0.658169 Tokens per Sec: 177.783142\n",
            "Epoch Step: 1 Loss: 0.373356 Tokens per Sec: 158.143326\n",
            "Epoch Step: 1 Loss: 0.620513 Tokens per Sec: 173.372635\n",
            "Epoch Step: 1 Loss: 0.250569 Tokens per Sec: 157.542694\n",
            "Epoch Step: 1 Loss: 0.555389 Tokens per Sec: 172.896469\n",
            "Epoch Step: 1 Loss: 0.188450 Tokens per Sec: 173.881210\n",
            "Epoch Step: 1 Loss: 0.484835 Tokens per Sec: 174.819748\n",
            "Epoch Step: 1 Loss: 0.093754 Tokens per Sec: 178.385208\n",
            "Epoch Step: 1 Loss: 0.387236 Tokens per Sec: 178.816589\n",
            "Epoch Step: 1 Loss: 0.078070 Tokens per Sec: 178.423111\n",
            "Epoch Step: 1 Loss: 0.312203 Tokens per Sec: 186.147873\n",
            "Epoch Step: 1 Loss: 0.089062 Tokens per Sec: 178.800583\n",
            "Epoch Step: 1 Loss: 0.246656 Tokens per Sec: 182.225616\n",
            "Epoch Step: 1 Loss: 0.042359 Tokens per Sec: 156.204254\n",
            "Epoch Step: 1 Loss: 0.201132 Tokens per Sec: 174.777985\n",
            "Epoch Step: 1 Loss: 0.034264 Tokens per Sec: 160.557770\n",
            "Epoch Step: 1 Loss: 0.163383 Tokens per Sec: 174.672195\n",
            "Epoch Step: 1 Loss: 0.019358 Tokens per Sec: 157.246719\n",
            "Epoch Step: 1 Loss: 0.235335 Tokens per Sec: 175.628494\n",
            "Epoch Step: 1 Loss: 0.019713 Tokens per Sec: 171.628952\n",
            "Epoch Step: 1 Loss: 0.193573 Tokens per Sec: 179.428970\n",
            "Epoch Step: 1 Loss: 0.021383 Tokens per Sec: 176.016129\n",
            "Epoch Step: 1 Loss: 0.148571 Tokens per Sec: 175.526886\n",
            "Epoch Step: 1 Loss: 0.024643 Tokens per Sec: 179.697052\n",
            "Epoch Step: 1 Loss: 0.083639 Tokens per Sec: 172.602295\n",
            "Epoch Step: 1 Loss: 0.021374 Tokens per Sec: 179.665573\n",
            "Epoch Step: 1 Loss: 0.081713 Tokens per Sec: 180.596008\n",
            "Epoch Step: 1 Loss: 0.011070 Tokens per Sec: 173.865677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model([1,  3,  2,  5,  4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW-6-5ufnboH",
        "outputId": "54ce514c-b745-4066-e8b9-e4b5b8fcf881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[1, 3, 2, 5, 4]])\n",
            "The resulting numeric sequence after 20 epochs of training is:\n",
            " tensor([[1, 3, 2, 5, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model([2,  5,  1,  4,  3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH0GxruWwewR",
        "outputId": "dd93a4d5-9029-4407-fdea-aba281d1baaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[2, 5, 1, 4, 3]])\n",
            "The resulting numeric sequence after 20 epochs of training is:\n",
            " tensor([[1, 5, 1, 4, 3]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model([2,  3,  1,  5, 4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hPaIKXJ1E17",
        "outputId": "dafa9b26-7227-4906-d449-4458c2062ff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[2, 3, 1, 5, 4]])\n",
            "The resulting numeric sequence after 20 epochs of training is:\n",
            " tensor([[1, 3, 1, 5, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model([[1,2,3,4,5]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um-xaPLM_OQF",
        "outputId": "ec268e12-8271-45a6-b492-8aed5c56373a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[[1, 2, 3, 4, 5]]])\n",
            "The resulting numeric sequence after 20 epochs of training is:\n",
            " tensor([[1, 2, 4, 3, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model([[5,4,3,2,1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec1T1eiG_ujE",
        "outputId": "93790a23-7631-471b-887d-caa10c1b2179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[[5, 4, 3, 2, 1]]])\n",
            "The resulting numeric sequence after 20 epochs of training is:\n",
            " tensor([[1, 2, 4, 3, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model([[1,3,5,2,4]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH7Y6tcm_7c1",
        "outputId": "4cc6f5ca-bd5c-4047-ba91-a4ea887669ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[[1, 3, 5, 2, 4]]])\n",
            "The resulting numeric sequence after 20 epochs of training is:\n",
            " tensor([[1, 2, 4, 3, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model([[2,3,4,2,3]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MX7dQriAUfw",
        "outputId": "49f0f06c-a97e-4321-a3c6-e9a5f2cf30ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[[2, 3, 4, 2, 3]]])\n",
            "The resulting numeric sequence after 20 epochs of training is:\n",
            " tensor([[1, 2, 3, 2, 3]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model([[1,1,1,1,1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLze03qyAjtD",
        "outputId": "4aa20d71-9a44-4852-9531-1073ad821f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[[1, 1, 1, 1, 1]]])\n",
            "The resulting numeric sequence after 20 epochs of training is:\n",
            " tensor([[1, 1, 1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model([[2,2,2,2,2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v91NF1j4Ap6F",
        "outputId": "bb66c8d2-334d-4560-a6bd-f69fc19ea022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[[2, 2, 2, 2, 2]]])\n",
            "The resulting numeric sequence after 20 epochs of training is:\n",
            " tensor([[1, 2, 2, 2, 2]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model([[0,1,2,3,4]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XBisIRhBgsJ",
        "outputId": "84122c48-63d7-48a2-b8bd-d3e4e7b7c5bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[[0, 1, 2, 3, 4]]])\n",
            "The resulting numeric sequence after 20 epochs of training is:\n",
            " tensor([[1, 2, 3, 4, 3]])\n"
          ]
        }
      ]
    }
  ]
}