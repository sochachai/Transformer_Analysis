{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4B89asubqeSzt+q3WDFfX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sochachai/Transformer_Analysis/blob/main/5_digits_result.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load packages"
      ],
      "metadata": {
        "id": "QadEcdM9HWsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check directory\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8gwuRviI0JD",
        "outputId": "529e3f89-d078-4cf2-a74c-1a77ea410263"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# confirm the assistant py file has been uploaded to the correct directory\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj093MmNI24A",
        "outputId": "2226b813-7b15-41c5-9d88-ef9e6e46362d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my_transformer_utils.py  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check Python version\n",
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9lyQC3sJbJs",
        "outputId": "0cab66ba-3950-4dad-d4d3-00f05fb224c3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install torch\n",
        "!pip install torch==2.2.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRb0L4jOJzuY",
        "outputId": "17b86ad1-09ca-435b-9d4f-13db3606b4f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.2.0\n",
            "  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.2.0 (from torch==2.2.0)\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.0) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 torch-2.2.0 triton-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check torch version\n",
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AWYB4ZIJnlB",
        "outputId": "711a9f8f-48ad-4fff-9988-5a1d9a44b9e3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZL5Plt3mvusS"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch\n",
        "import math\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "# Issue caused by torch version described below:\n",
        "# the original package should be pyitcast.transformer_utils\n",
        "# the problem is that pyitcast.transformer_utils relies on an old version of torch (1.3.1 should work)\n",
        "# and causes the error \"IndexError: invalid index of a 0-dim tensor. Use `tensor.item()` in Python...\"\n",
        "# but the installation of an old version of torch that match pyitcast.transformer is not trivial\n",
        "# versions of 1.11.0 or after is not compatible with pyitcast.transformer and installation of them will not\n",
        "# solve the issue\n",
        "# To solve this issue:\n",
        "# download the pyitcast.transformer_utils (open by clicking the error message) as a py file\n",
        "# modify the last line of the SimpleLossCompute class from \"return loss.data[0] * norm\"\n",
        "# to \"return loss.data * norm\"\n",
        "\n",
        "from my_transformer_utils import Batch\n",
        "from my_transformer_utils import run_epoch\n",
        "from my_transformer_utils import greedy_decode\n",
        "from my_transformer_utils import get_std_opt # get_std_opt is based on Adam optimizer\n",
        "from my_transformer_utils import LabelSmoothing # offset human label errors to prevent overfitting\n",
        "from my_transformer_utils import SimpleLossCompute # calculate loss after smoothing, use cross_entropy_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construct the class of Embeddings and Positional Encoding."
      ],
      "metadata": {
        "id": "UBTCCLP4Hc3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        '''\n",
        "        :param d_model: embedding dimension\n",
        "        :param vocab: size of vocabulary\n",
        "        '''\n",
        "        # Initialization\n",
        "        super(Embeddings, self).__init__()\n",
        "        # Defrine a word embedding object\n",
        "        self.lut = nn.Embedding(vocab, d_model)\n",
        "        # Instantiate d_model\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        :param x: tensor representing the original text\n",
        "        '''\n",
        "        return self.lut(x) * math.sqrt(self.d_model)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout, max_len = 5000):\n",
        "        '''\n",
        "        :param d_model: dimension of the encoding\n",
        "        :param dropout: dropout rate from 0 to 1\n",
        "        :param max_len: the maximum length of a sentence\n",
        "        '''\n",
        "        # Inherit the initialization of nn.Module\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        # Objectify dropout\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Inherit a positional encoder matrix, max_len * d_model\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "\n",
        "        # Inherit an absolute position matrix, max_len * 1\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "\n",
        "        # Define the conversion matrix, initialization with gap = 2\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0)/d_model))\n",
        "\n",
        "        # Copy the absolute position matrix to the positional encoder matrix\n",
        "        # by sine and cosine wave according to the parity of column indices\n",
        "        pe[:, 0::2] = torch.sin(position * div_term) # even indiced columns are imputed by sine\n",
        "        pe[:, 1::2] = torch.cos(position * div_term) # odd indiced columns are imputed by cosine\n",
        "\n",
        "        # Extend pe to 3-dimensional tensor\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        # Register pe to a buffer, the buffer is not a parameter of the class\n",
        "        # the buffer will not be updated along with the model update\n",
        "        # but it can be loaded along with the model\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        :param x: Tensor of text\n",
        "        :return: x + the positional encoding\n",
        "        '''\n",
        "        # Shrink the size of pe to save storage\n",
        "        # by converting the second dimension, i.e. the dimension of max_len\n",
        "        # to the size of the sentence len of x, i.e. the second dimension of x\n",
        "        x = x + Variable(self.pe[:,:x.size(1)], requires_grad = False) # False: pe will not be updated\n",
        "        return self.dropout(x)\n",
        "\n",
        "def attention(query, key, value, mask = None, dropout = None):\n",
        "    '''\n",
        "    :param query: vectorized original text\n",
        "    :param key: key words of text\n",
        "    :param value: the original value of key, summarization of query\n",
        "    :param mask: hide words to avoid data leakage\n",
        "    :param dropout: dropout rate of neural network\n",
        "    :return:\n",
        "    '''\n",
        "    d_k = query.size(-1)\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, -1e9) # compare each position with 0\n",
        "\n",
        "    p_attn = F.softmax(scores, dim = -1)\n",
        "    if dropout is not None:\n",
        "        p_attn = dropout(p_attn)\n",
        "\n",
        "    return torch.matmul(p_attn, value), p_attn\n",
        "\n",
        "def clones(module, N):\n",
        "    '''\n",
        "    :param module: one attention layer\n",
        "    :param N: the number of module\n",
        "    '''\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)]) # deepcopy uses a different memory\n",
        "\n",
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, head, embedding_dim, dropout = 0.1):\n",
        "        '''\n",
        "        :param head: the number of heads\n",
        "        :param embedding_dim: the embedding dimension\n",
        "        :param dropout: default dropout rate set to 0.1\n",
        "        '''\n",
        "        # Inherit the initialization\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        # head must be an integral factor of embedding_dim\n",
        "        assert embedding_dim % head == 0\n",
        "        # each head is assigned with the following dimension\n",
        "        self.d_k = embedding_dim // head # division in the integral domain Z\n",
        "        # substantiate head\n",
        "        self.head = head\n",
        "        # create linear layers, we need 4 of them for Q, K, V and the final connection\n",
        "        self.linears = clones(nn.Linear(embedding_dim, embedding_dim), 4)\n",
        "        # create the attention and dropout rate\n",
        "        self.attn = None\n",
        "        self.dropout = nn.Dropout(p = dropout)\n",
        "\n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1)\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        # We have 4 linears and only zipping the first 3 with Q, K, V, the last linear is not used.\n",
        "        # view(batch_size, -1, self.head, self.d_k).transpose(1,2)\n",
        "        # is not the same with view(batch_size, self.head, -1, self.d_k)\n",
        "        # self.head and self.d_k should be neighboring to get embedding_dim in order for the tensor\n",
        "        # to interpret the relationship between the meaning of words of their positions in a sentence\n",
        "\n",
        "        query, key, value = \\\n",
        "            [model(x).view(batch_size, -1, self.head, self.d_k).transpose(1,2)\n",
        "             for model, x in zip(self.linears, (query, key, value))]\n",
        "\n",
        "        x, self.attn = attention(query, key, value, mask = mask, dropout = self.dropout)\n",
        "\n",
        "        # Reshape x\n",
        "        # must use contiguous method after the transpose before the view method\n",
        "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.head * self.d_k)\n",
        "\n",
        "        # Pass x to the 4th linear layer\n",
        "        return self.linears[-1](x)\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        '''\n",
        "        :param d_model: embedding dimension\n",
        "        :param d_ff: transitional dimension\n",
        "        :param dropout: default dropout set to 0.1\n",
        "        '''\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.w1 = nn.Linear(d_model, d_ff)\n",
        "        self.w2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w2(self.dropout(F.relu(self.w1(x))))\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, features, eps = 1e-6):\n",
        "        '''\n",
        "        :param features: embedding dimension\n",
        "        :param eps: avoid zero denominator\n",
        "        '''\n",
        "        super(LayerNorm, self).__init__()\n",
        "        # nn.Parameter formats the variables to intrinsic parameters\n",
        "        # they will be updated along with the model in contrast with buffer\n",
        "        self.a2 = nn.Parameter(torch.ones(features))\n",
        "        self.b2 = nn.Parameter(torch.zeros(features))\n",
        "        # initialization of eps\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        :param x: the output of previous layer\n",
        "        :return: numerical standardized x\n",
        "        '''\n",
        "        mean = x.mean(-1, keepdim = True)\n",
        "        std = x.std(-1, keepdim = True)\n",
        "        return self.a2 * (x - mean) / (std + self.eps) + self.b2\n",
        "\n",
        "class SublayerConnection(nn.Module):\n",
        "    def __init__(self, size, dropout = 0.1):\n",
        "        '''\n",
        "        :param size: embedding size\n",
        "        :param dropout: deactivation of neurons to avoid overfitting\n",
        "        '''\n",
        "        super(SublayerConnection, self).__init__()\n",
        "        self.norm = LayerNorm(size)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        '''\n",
        "        :param x: the output of previous layer\n",
        "        :param sublayer: a function, e.g. Multihead_Attention, PositionwiseFeedForward etc.\n",
        "        :return: x plus sublayer functioning on normed x with dropout\n",
        "        '''\n",
        "        return x + self.dropout(sublayer(self.norm(x)))\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "        '''\n",
        "        :param size: embedding dimension\n",
        "        :param self_attn: attention\n",
        "        :param feed_forward: positionwise feed forward\n",
        "        :param dropout: avoid overfitting\n",
        "        '''\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = self_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
        "        self.size = size\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        '''\n",
        "        :param x: output of previous layer\n",
        "        :param mask: tensor mask to prevent data leakage\n",
        "        '''\n",
        "        # input matrix followed by operating function, returns an output matrix\n",
        "        # sublayer(x, function) will return function(x)\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask)) # the forward function of multihead attention\n",
        "        return self.sublayer[1](x, self.feed_forward) # the forward function of pointwise feedforward\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    # Encoder is a collection of Encoder Layers\n",
        "    def __init__(self, layer, N):\n",
        "        '''\n",
        "        :param layer: one encoder layer\n",
        "        :param N: the number of encoder layers\n",
        "        '''\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        for layer in self.layers: x = layer(x, mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
        "        '''\n",
        "        :param size: embedding dimension\n",
        "        :param self_attn: masked multihead attention\n",
        "        :param src_attn: multihead attention\n",
        "        :param feed_forward: pointwise feed forward\n",
        "        :param dropout: avoid overfitting\n",
        "        '''\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.src_attn = src_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        # 3 sublayer for a decoder layer\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
        "\n",
        "    def forward(self, x, memory, source_mask, target_mask):\n",
        "        '''\n",
        "        :param x: output of previous layer\n",
        "        :param memory: result of encoder\n",
        "        :param source_mask: delete unnecessary info to improve model performance\n",
        "        :param target_mask: hide info to prevent data leakage\n",
        "        :return: output tensor\n",
        "        '''\n",
        "        m = memory\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, target_mask))\n",
        "        # for second layer, Q = x, K = V = m\n",
        "        x = self.sublayer[1](x, lambda x: self.self_attn(x, m, m, source_mask))\n",
        "        return self.sublayer[2](x, self.feed_forward)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    # Decoder is a collection of Decoder Layers\n",
        "    def __init__(self, layer, N):\n",
        "        '''\n",
        "        :param layer: decoder layer\n",
        "        :param N: the number of decoder layers\n",
        "        '''\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, memory, source_mask, target_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, memory, source_mask, target_mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, d_model, vocab_size):\n",
        "        '''\n",
        "        :param d_model: embedding dimension\n",
        "        :param vocab_size: the size of the vocabulary\n",
        "        '''\n",
        "        super(Generator, self).__init__()\n",
        "        self.project = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.project(x), dim = -1)\n",
        "\n",
        "class EncoderDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder, source_embed, target_embed, generator):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = source_embed\n",
        "        self.tgt_embed = target_embed\n",
        "        self.generator = generator\n",
        "\n",
        "    def forward(self, source, target, source_mask, target_mask):\n",
        "        # encoded source used as memory in decode function\n",
        "        return self.decode(self.encode(source, source_mask), source_mask,\n",
        "                           target, target_mask)\n",
        "\n",
        "    def encode(self, source, source_mask):\n",
        "        return self.encoder(self.src_embed(source), source_mask)\n",
        "\n",
        "    def decode(self, memory, source_mask, target, target_mask):\n",
        "        # embedded target as x in the decoder function\n",
        "        return self.decoder(self.tgt_embed(target), memory, source_mask, target_mask)\n",
        "\n",
        "def make_model(source_vocab, target_vocab, N=6,\\\n",
        "               d_model=512, d_ff=2048, head=8, dropout=0.1):\n",
        "    c = copy.deepcopy\n",
        "    attn = MultiHeadedAttention(head, d_model)\n",
        "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "    position = PositionalEncoding(d_model, dropout)\n",
        "    model = EncoderDecoder(\n",
        "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
        "        Decoder(DecoderLayer(d_model, c(attn), c(attn),c(ff), dropout), N),\n",
        "        # note the order of vocab_size and d_model;\n",
        "        # nn.Embedding is not the same with Embeddings;\n",
        "        # check Embedding_Encoder.py for more;\n",
        "        nn.Sequential(Embeddings(d_model, source_vocab), c(position)),\n",
        "        nn.Sequential(Embeddings(d_model, target_vocab), c(position)),\n",
        "        Generator(d_model, target_vocab)\n",
        "    )\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1: nn.init.xavier_uniform_(p) # initialization: make p uniformly sampled; check xavier_uniform for details\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Task: Test the language model's capability to copy a sequence of numbers\n",
        "      Input a list of numbers, the output should be the identical list of numbers\n",
        "SubTask: Write a data generator to generate sample data for model testing\n",
        "'''\n",
        "\n",
        "# use a function to generate data\n",
        "def data_generator(V, batch_size, num_batch):\n",
        "    '''\n",
        "    :param V: the maximal data value + 1\n",
        "    :param batch_size: sample data size of one round of training after which model parameters are updated\n",
        "    :param num_batch: number of rounds of training\n",
        "    '''\n",
        "    for i in range(num_batch):\n",
        "        # data value from 1 to V-1, with data matrix shape = batch_size times 10\n",
        "        data = torch.from_numpy(np.random.randint(1, V, size = (batch_size, 10)))\n",
        "\n",
        "        # set starting position label\n",
        "        data[:, 0] = 1\n",
        "\n",
        "        # for a copy task source data and target data should be the same\n",
        "        # no gradient calculation involved\n",
        "        source = Variable(data, requires_grad = False)\n",
        "        target = Variable(data, requires_grad = False)\n",
        "        yield Batch(source, target)\n",
        "\n",
        "\n",
        "def run(model, loss, epochs=10):\n",
        "    '''\n",
        "    :param model: model\n",
        "    :param loss: loss function\n",
        "    :param epochs: number of rounds of training\n",
        "    '''\n",
        "    for epoch in range(epochs):\n",
        "        # train model, update model parameters\n",
        "        model.train()\n",
        "        run_epoch(data_generator(V, 200, 8), model, loss)\n",
        "        # evaluate model, no parameters update\n",
        "        model.eval()\n",
        "        run_epoch(data_generator(V, 50, 8), model, loss)\n"
      ],
      "metadata": {
        "id": "q5g__pE7CWic"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiate a model."
      ],
      "metadata": {
        "id": "KEdHXxGxHELW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate variables\n",
        "V = 6\n",
        "batch_size = 20\n",
        "num_batch = 30\n",
        "\n",
        "# get model\n",
        "model = make_model(V, V, N = 6)\n",
        "\n",
        "# get optimizer\n",
        "model_optimizer = get_std_opt(model)\n",
        "\n",
        "# get smooth criterion\n",
        "criterion = LabelSmoothing(size = V, padding_idx = 0, smoothing = 0.0)\n",
        "\n",
        "# get loss function\n",
        "# model as an EncoderDecoder whose last element is a generator object\n",
        "loss = SimpleLossCompute(model.generator, criterion, model_optimizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_FcF3EqEmy8",
        "outputId": "0778c04b-8a6c-4487-d10e-8cce2701eb33"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 epochs of model training."
      ],
      "metadata": {
        "id": "Gf1eGbnNFeB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model training\n",
        "epochs = 10\n",
        "if __name__ == '__main__':\n",
        "    run(model, loss, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLdoV2-vsitL",
        "outputId": "ddfc5932-f81f-453c-d098-1f30f700c636"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch Step: 1 Loss: 2.037391 Tokens per Sec: 157.054108\n",
            "Epoch Step: 1 Loss: 1.850224 Tokens per Sec: 152.114258\n",
            "Epoch Step: 1 Loss: 1.716174 Tokens per Sec: 171.577301\n",
            "Epoch Step: 1 Loss: 1.431418 Tokens per Sec: 179.027100\n",
            "Epoch Step: 1 Loss: 1.482326 Tokens per Sec: 170.137909\n",
            "Epoch Step: 1 Loss: 1.316452 Tokens per Sec: 179.484711\n",
            "Epoch Step: 1 Loss: 1.372549 Tokens per Sec: 173.278351\n",
            "Epoch Step: 1 Loss: 1.254976 Tokens per Sec: 168.027817\n",
            "Epoch Step: 1 Loss: 1.343951 Tokens per Sec: 178.864838\n",
            "Epoch Step: 1 Loss: 1.264327 Tokens per Sec: 148.663406\n",
            "Epoch Step: 1 Loss: 1.330258 Tokens per Sec: 169.095764\n",
            "Epoch Step: 1 Loss: 1.178638 Tokens per Sec: 180.879425\n",
            "Epoch Step: 1 Loss: 1.289549 Tokens per Sec: 175.482727\n",
            "Epoch Step: 1 Loss: 1.082457 Tokens per Sec: 181.511505\n",
            "Epoch Step: 1 Loss: 1.226902 Tokens per Sec: 177.647034\n",
            "Epoch Step: 1 Loss: 1.094218 Tokens per Sec: 179.631683\n",
            "Epoch Step: 1 Loss: 1.248441 Tokens per Sec: 183.396729\n",
            "Epoch Step: 1 Loss: 0.983338 Tokens per Sec: 181.474365\n",
            "Epoch Step: 1 Loss: 1.132679 Tokens per Sec: 180.271881\n",
            "Epoch Step: 1 Loss: 1.111620 Tokens per Sec: 153.491531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the model's capibility of copying the original sequence with greedy decode after 10 epochs of training."
      ],
      "metadata": {
        "id": "HpkNeAqqr4Yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(an_integer_sequence_of_size_5):\n",
        "    # greedy decode\n",
        "    # enter evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # get source input\n",
        "    source = Variable(torch.LongTensor([an_integer_sequence_of_size_5]))\n",
        "\n",
        "    # get source mask\n",
        "    # 1 for no masking\n",
        "    source_mask = Variable(torch.ones(1, 1, 5))\n",
        "\n",
        "    # get result\n",
        "    result = greedy_decode(model, source, source_mask, max_len=5, start_symbol=1)\n",
        "    print(f\"The source numeric sequence is:\\n {source}\")\n",
        "    print(f\"The resulting numeric sequence after {epochs} epochs of training is:\\n {result}\")\n",
        "\n",
        "test_model([1,  3,  2,  5,  4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cfZ2TBzryq5",
        "outputId": "4d956bbf-69ce-4143-bff4-15a1af253e64"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[1, 3, 2, 5, 4]])\n",
            "The resulting numeric sequence after 10 epochs of training is:\n",
            " tensor([[1, 3, 2, 5, 3]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the model's capibility of copying the original sequence with greedy decode after an extra of 20 epochs of training."
      ],
      "metadata": {
        "id": "tEXOpUlSGGiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model training\n",
        "epochs = 20\n",
        "if __name__ == '__main__':\n",
        "    run(model, loss, epochs)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5SwQh1vGDRJ",
        "outputId": "7b9fb8a5-823e-4884-9321-127931aae86a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch Step: 1 Loss: 1.239350 Tokens per Sec: 162.733932\n",
            "Epoch Step: 1 Loss: 0.908190 Tokens per Sec: 171.653259\n",
            "Epoch Step: 1 Loss: 0.996257 Tokens per Sec: 181.329926\n",
            "Epoch Step: 1 Loss: 0.741328 Tokens per Sec: 148.147736\n",
            "Epoch Step: 1 Loss: 0.963049 Tokens per Sec: 166.191589\n",
            "Epoch Step: 1 Loss: 0.628003 Tokens per Sec: 167.297852\n",
            "Epoch Step: 1 Loss: 0.933253 Tokens per Sec: 169.863144\n",
            "Epoch Step: 1 Loss: 0.629011 Tokens per Sec: 151.229950\n",
            "Epoch Step: 1 Loss: 0.831857 Tokens per Sec: 168.031021\n",
            "Epoch Step: 1 Loss: 0.548762 Tokens per Sec: 174.622253\n",
            "Epoch Step: 1 Loss: 0.777321 Tokens per Sec: 168.225006\n",
            "Epoch Step: 1 Loss: 0.414798 Tokens per Sec: 180.782944\n",
            "Epoch Step: 1 Loss: 0.658169 Tokens per Sec: 177.783142\n",
            "Epoch Step: 1 Loss: 0.373356 Tokens per Sec: 158.143326\n",
            "Epoch Step: 1 Loss: 0.620513 Tokens per Sec: 173.372635\n",
            "Epoch Step: 1 Loss: 0.250569 Tokens per Sec: 157.542694\n",
            "Epoch Step: 1 Loss: 0.555389 Tokens per Sec: 172.896469\n",
            "Epoch Step: 1 Loss: 0.188450 Tokens per Sec: 173.881210\n",
            "Epoch Step: 1 Loss: 0.484835 Tokens per Sec: 174.819748\n",
            "Epoch Step: 1 Loss: 0.093754 Tokens per Sec: 178.385208\n",
            "Epoch Step: 1 Loss: 0.387236 Tokens per Sec: 178.816589\n",
            "Epoch Step: 1 Loss: 0.078070 Tokens per Sec: 178.423111\n",
            "Epoch Step: 1 Loss: 0.312203 Tokens per Sec: 186.147873\n",
            "Epoch Step: 1 Loss: 0.089062 Tokens per Sec: 178.800583\n",
            "Epoch Step: 1 Loss: 0.246656 Tokens per Sec: 182.225616\n",
            "Epoch Step: 1 Loss: 0.042359 Tokens per Sec: 156.204254\n",
            "Epoch Step: 1 Loss: 0.201132 Tokens per Sec: 174.777985\n",
            "Epoch Step: 1 Loss: 0.034264 Tokens per Sec: 160.557770\n",
            "Epoch Step: 1 Loss: 0.163383 Tokens per Sec: 174.672195\n",
            "Epoch Step: 1 Loss: 0.019358 Tokens per Sec: 157.246719\n",
            "Epoch Step: 1 Loss: 0.235335 Tokens per Sec: 175.628494\n",
            "Epoch Step: 1 Loss: 0.019713 Tokens per Sec: 171.628952\n",
            "Epoch Step: 1 Loss: 0.193573 Tokens per Sec: 179.428970\n",
            "Epoch Step: 1 Loss: 0.021383 Tokens per Sec: 176.016129\n",
            "Epoch Step: 1 Loss: 0.148571 Tokens per Sec: 175.526886\n",
            "Epoch Step: 1 Loss: 0.024643 Tokens per Sec: 179.697052\n",
            "Epoch Step: 1 Loss: 0.083639 Tokens per Sec: 172.602295\n",
            "Epoch Step: 1 Loss: 0.021374 Tokens per Sec: 179.665573\n",
            "Epoch Step: 1 Loss: 0.081713 Tokens per Sec: 180.596008\n",
            "Epoch Step: 1 Loss: 0.011070 Tokens per Sec: 173.865677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model([1,  3,  2,  5,  4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW-6-5ufnboH",
        "outputId": "54ce514c-b745-4066-e8b9-e4b5b8fcf881"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[1, 3, 2, 5, 4]])\n",
            "The resulting numeric sequence after 20 epochs of training is:\n",
            " tensor([[1, 3, 2, 5, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model([2,  5,  1,  4,  3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH0GxruWwewR",
        "outputId": "dd93a4d5-9029-4407-fdea-aba281d1baaa"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[2, 5, 1, 4, 3]])\n",
            "The resulting numeric sequence after 20 epochs of training is:\n",
            " tensor([[1, 5, 1, 4, 3]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model([2,  3,  1,  5, 4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hPaIKXJ1E17",
        "outputId": "dafa9b26-7227-4906-d449-4458c2062ff0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[2, 3, 1, 5, 4]])\n",
            "The resulting numeric sequence after 20 epochs of training is:\n",
            " tensor([[1, 3, 1, 5, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model([[1,2,3,4,5]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um-xaPLM_OQF",
        "outputId": "ec268e12-8271-45a6-b492-8aed5c56373a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[[1, 2, 3, 4, 5]]])\n",
            "The resulting numeric sequence after 20 epochs of training is:\n",
            " tensor([[1, 2, 4, 3, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model([[5,4,3,2,1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec1T1eiG_ujE",
        "outputId": "93790a23-7631-471b-887d-caa10c1b2179"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[[5, 4, 3, 2, 1]]])\n",
            "The resulting numeric sequence after 20 epochs of training is:\n",
            " tensor([[1, 2, 4, 3, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model([[1,3,5,2,4]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH7Y6tcm_7c1",
        "outputId": "4cc6f5ca-bd5c-4047-ba91-a4ea887669ae"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[[1, 3, 5, 2, 4]]])\n",
            "The resulting numeric sequence after 20 epochs of training is:\n",
            " tensor([[1, 2, 4, 3, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model([[2,3,4,2,3]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MX7dQriAUfw",
        "outputId": "49f0f06c-a97e-4321-a3c6-e9a5f2cf30ef"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[[2, 3, 4, 2, 3]]])\n",
            "The resulting numeric sequence after 20 epochs of training is:\n",
            " tensor([[1, 2, 3, 2, 3]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model([[1,1,1,1,1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLze03qyAjtD",
        "outputId": "4aa20d71-9a44-4852-9531-1073ad821f46"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[[1, 1, 1, 1, 1]]])\n",
            "The resulting numeric sequence after 20 epochs of training is:\n",
            " tensor([[1, 1, 1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model([[2,2,2,2,2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v91NF1j4Ap6F",
        "outputId": "bb66c8d2-334d-4560-a6bd-f69fc19ea022"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[[2, 2, 2, 2, 2]]])\n",
            "The resulting numeric sequence after 20 epochs of training is:\n",
            " tensor([[1, 2, 2, 2, 2]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model([[0,1,2,3,4]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XBisIRhBgsJ",
        "outputId": "84122c48-63d7-48a2-b8bd-d3e4e7b7c5bc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source numeric sequence is:\n",
            " tensor([[[0, 1, 2, 3, 4]]])\n",
            "The resulting numeric sequence after 20 epochs of training is:\n",
            " tensor([[1, 2, 3, 4, 3]])\n"
          ]
        }
      ]
    }
  ]
}